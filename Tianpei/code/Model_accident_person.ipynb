{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on accident and person data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? \n",
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "%reset \n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "from numpy import nan as NA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score as auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and make labels consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load labels\n"
     ]
    }
   ],
   "source": [
    "print(\"Load labels\")\n",
    "label_file = pd.read_csv(\"./train/labels_ext.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[708569, 260]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = pd.read_csv(\"./train/joint_accident_person_train_ext.csv\", index_col=0)\n",
    "n_train, n_dim = Xtrain.shape\n",
    "print([n_train, n_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = pd.merge(Xtrain, label_file, on=['ID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = temp['DRUNK_DR'].apply(lambda x: x*1 ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.unique(Xtrain['ID'].values)\n",
    "n_valid = int(len(indices)*0.3)\n",
    "perm_indices = np.random.permutation(indices)\n",
    "train_indices = perm_indices[:n_valid]\n",
    "valid_indices = perm_indices[n_valid:]\n",
    "\n",
    "# We will now group each accident by ID.\n",
    "grouped = Xtrain.groupby('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_ids = {key : grouped.indices[key] for key in train_indices}\n",
    "te_ids = {key : grouped.indices[key] for key in valid_indices}\n",
    "%xdel grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally, we turn the dictionaries we created above into lists of row numbers.\n",
    "# We can then use these row numbers to build our train/test split.\n",
    "train_ids = []\n",
    "for key in tr_ids:\n",
    "    for ind in tr_ids[key].tolist():\n",
    "        train_ids.append(ind)\n",
    "\n",
    "valid_ids = []\n",
    "for key in te_ids:\n",
    "    for ind in te_ids[key].tolist():\n",
    "        valid_ids.append(ind)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain.drop('ID', axis= 1, inplace=True)\n",
    "print(\"Splitting data\")\n",
    "%xdel label_file\n",
    "%xdel tr_ids\n",
    "%xdel te_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain_c = Xtrain.ix[train_ids].to_sparse()\n",
    "Xeval = Xtrain.ix[valid_ids].to_sparse()\n",
    "Ytrain_c = y[train_ids].to_sparse()\n",
    "Yeval = y[valid_ids].to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel Xtrain\n",
    "\n",
    "%xdel valid_ids\n",
    "%xdel train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Load data into sparse matrix\")\n",
    "dtrain = xgb.DMatrix(data=Xtrain_c, missing = NA, label= Ytrain_c)\n",
    "%xdel Xtrain_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deval  = xgb.DMatrix(data=Xeval, missing = NA, label = Yeval)\n",
    "%xdel Xeval\n",
    "print(\"Specifying the parameters ... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'max_depth': 12,\n",
    "         'eta': 0.02,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'silent': 0,\n",
    "         'eval_metric': 'auc',\n",
    "         'alpha': 0,\n",
    "         'lambda': 1,\n",
    "         'nthread': 8,\n",
    "         'objective': 'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "watchlist = [(deval, 'eval'), (dtrain, 'train')]\n",
    "num_round = 520\n",
    "print(\"Training ... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Saving the model\")\n",
    "bst.save_model('./models/xgb_acc_per.model')\n",
    "bst.dump_model('./models/xgb_raw_acc_per.txt')\n",
    "\n",
    "dtrain.save_binary('./models/binary/dtrain.buffer')\n",
    "deval.save_binary('./models/binary/deval.buffer')\n",
    "\n",
    "%xdel dtrain\n",
    "%xdel deval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest = pd.read_csv(\"./test/joint_accident_person_test_ext.csv\", index_col=0)\n",
    "ID= Xtest['ID'].astype(np.int64)\n",
    "Xtest.drop('ID', axis= 1, inplace=True)\n",
    "print(\"Load test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqueID = np.unique(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniqueID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest= xgb.DMatrix(data=Xtest.values, missing = NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction\")\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest.save_binary('./models/binary/dtest.buffer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"submit\")\n",
    "predict_df = pd.DataFrame(data={'ID': ID.values, 'prob': preds})\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict_df.groupby('ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_predict = predict_df.groupby('ID')\n",
    "prediction = grouped_predict.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(data={'ID': prediction.index, 'DRUNK_DR': prediction['prob'].values})\n",
    "submit.to_csv('fars_submit.csv', index = False)\n",
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
