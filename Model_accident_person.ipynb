{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on accident and person data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset \n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "from numpy import nan as NA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score as auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and make labels consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load labels\n"
     ]
    }
   ],
   "source": [
    "print(\"Load labels\")\n",
    "label_file = pd.read_csv(\"./train/labels_ext.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[708569, 260]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = pd.read_csv(\"./train/joint_accident_person_train_ext.csv\", index_col=0)\n",
    "n_train, n_dim = Xtrain.shape\n",
    "print([n_train, n_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = pd.merge(Xtrain, label_file, on=['ID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = temp['DRUNK_DR'].apply(lambda x: x*1 ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data\n"
     ]
    }
   ],
   "source": [
    "Xtrain.drop('ID', axis= 1, inplace=True)\n",
    "print(\"Splitting data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain_c, Xeval, Ytrain_c, Yeval = train_test_split(Xtrain.values, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel Xtrain\n",
    "%xdel label_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable           Type        Data/Info\n",
      "----------------------------------------\n",
      "NA                 float       nan\n",
      "Xeval              ndarray     212571x259: 55055889 elems, type `float64`, 440447112 bytes (420.04309844970703 Mb)\n",
      "Xtrain_c           ndarray     495998x259: 128463482 elems, type `float64`, 1027707856 bytes (980.0985870361328 Mb)\n",
      "Yeval              ndarray     212571: 212571 elems, type `int64`, 1700568 bytes (1.6217880249023438 Mb)\n",
      "Ytrain_c           ndarray     495998: 495998 elems, type `int64`, 3967984 bytes (3.7841644287109375 Mb)\n",
      "auc                function    <function roc_auc_score at 0x7f2f7d8e1ae8>\n",
      "n_dim              int         260\n",
      "n_train            int         708569\n",
      "np                 module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "os                 module      <module 'os' from '/home/<...>da3/lib/python3.5/os.py'>\n",
      "pd                 module      <module 'pandas' from '/h<...>ages/pandas/__init__.py'>\n",
      "plt                module      <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "sns                module      <module 'seaborn' from '/<...>ges/seaborn/__init__.py'>\n",
      "sqlite3            module      <module 'sqlite3' from '/<...>3.5/sqlite3/__init__.py'>\n",
      "train_test_split   function    <function train_test_split at 0x7f2f7c888268>\n",
      "xgb                module      <module 'xgboost' from '/<...>ges/xgboost/__init__.py'>\n",
      "y                  ndarray     708569: 708569 elems, type `int64`, 5668552 bytes (5.405952453613281 Mb)\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data into sparse matrix\n",
      "Specifying the parameters ... \n"
     ]
    }
   ],
   "source": [
    "print(\"Load data into sparse matrix\")\n",
    "dtrain = xgb.DMatrix(data=Xtrain_c, missing = NA, label= Ytrain_c)\n",
    "deval  = xgb.DMatrix(data=Xeval, missing = NA, label = Yeval)\n",
    "print(\"Specifying the parameters ... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NameError: name 'Xtrain_c' is not defined\n",
      "NameError: name 'Xeval' is not defined\n",
      "Variable           Type        Data/Info\n",
      "----------------------------------------\n",
      "NA                 float       nan\n",
      "Yeval              ndarray     212571: 212571 elems, type `int64`, 1700568 bytes (1.6217880249023438 Mb)\n",
      "Ytrain_c           ndarray     495998: 495998 elems, type `int64`, 3967984 bytes (3.7841644287109375 Mb)\n",
      "auc                function    <function roc_auc_score at 0x7f2f7d8e1ae8>\n",
      "deval              DMatrix     <xgboost.core.DMatrix object at 0x7f2f7c8bc0b8>\n",
      "dtrain             DMatrix     <xgboost.core.DMatrix object at 0x7f2f7c8bc080>\n",
      "n_dim              int         260\n",
      "n_train            int         708569\n",
      "np                 module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "os                 module      <module 'os' from '/home/<...>da3/lib/python3.5/os.py'>\n",
      "param              dict        n=10\n",
      "pd                 module      <module 'pandas' from '/h<...>ages/pandas/__init__.py'>\n",
      "plt                module      <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "sns                module      <module 'seaborn' from '/<...>ges/seaborn/__init__.py'>\n",
      "sqlite3            module      <module 'sqlite3' from '/<...>3.5/sqlite3/__init__.py'>\n",
      "train_test_split   function    <function train_test_split at 0x7f2f7c888268>\n",
      "xgb                module      <module 'xgboost' from '/<...>ges/xgboost/__init__.py'>\n",
      "y                  ndarray     708569: 708569 elems, type `int64`, 5668552 bytes (5.405952453613281 Mb)\n"
     ]
    }
   ],
   "source": [
    "%xdel Xtrain_c\n",
    "%xdel Xeval\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'max_depth': 12,\n",
    "         'eta': 0.02,\n",
    "         'subsample': 0.7,\n",
    "         'colsample_bytree': 0.8,\n",
    "         'silent': 0,\n",
    "         'eval_metric': 'auc',\n",
    "         'alpha': 0,\n",
    "         'lambda': 1,\n",
    "         'nthread': 8,\n",
    "         'objective': 'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ... \n"
     ]
    }
   ],
   "source": [
    "watchlist = [(deval, 'eval'), (dtrain, 'train')]\n",
    "num_round = 520\n",
    "print(\"Training ... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.816793\ttrain-auc:0.831687\n",
      "[1]\teval-auc:0.825441\ttrain-auc:0.840354\n",
      "[2]\teval-auc:0.829731\ttrain-auc:0.845102\n",
      "[3]\teval-auc:0.832145\ttrain-auc:0.847612\n",
      "[4]\teval-auc:0.833571\ttrain-auc:0.849153\n",
      "[5]\teval-auc:0.834688\ttrain-auc:0.850574\n",
      "[6]\teval-auc:0.835894\ttrain-auc:0.852529\n",
      "[7]\teval-auc:0.836466\ttrain-auc:0.853303\n",
      "[8]\teval-auc:0.837231\ttrain-auc:0.854312\n",
      "[9]\teval-auc:0.837713\ttrain-auc:0.854804\n",
      "[10]\teval-auc:0.838087\ttrain-auc:0.855431\n",
      "[11]\teval-auc:0.838762\ttrain-auc:0.856217\n",
      "[12]\teval-auc:0.838954\ttrain-auc:0.856522\n",
      "[13]\teval-auc:0.839272\ttrain-auc:0.856997\n",
      "[14]\teval-auc:0.839488\ttrain-auc:0.857295\n",
      "[15]\teval-auc:0.839868\ttrain-auc:0.857791\n",
      "[16]\teval-auc:0.840244\ttrain-auc:0.858400\n",
      "[17]\teval-auc:0.840450\ttrain-auc:0.858638\n",
      "[18]\teval-auc:0.841010\ttrain-auc:0.859184\n",
      "[19]\teval-auc:0.841302\ttrain-auc:0.859498\n",
      "[20]\teval-auc:0.841563\ttrain-auc:0.859941\n",
      "[21]\teval-auc:0.841915\ttrain-auc:0.860492\n",
      "[22]\teval-auc:0.842331\ttrain-auc:0.861009\n",
      "[23]\teval-auc:0.842436\ttrain-auc:0.861252\n",
      "[24]\teval-auc:0.842735\ttrain-auc:0.861734\n",
      "[25]\teval-auc:0.843268\ttrain-auc:0.862270\n",
      "[26]\teval-auc:0.843735\ttrain-auc:0.862839\n",
      "[27]\teval-auc:0.844138\ttrain-auc:0.863340\n",
      "[28]\teval-auc:0.844257\ttrain-auc:0.863509\n",
      "[29]\teval-auc:0.844322\ttrain-auc:0.863679\n",
      "[30]\teval-auc:0.844615\ttrain-auc:0.864153\n",
      "[31]\teval-auc:0.844820\ttrain-auc:0.864452\n",
      "[32]\teval-auc:0.845014\ttrain-auc:0.864740\n",
      "[33]\teval-auc:0.845236\ttrain-auc:0.865132\n",
      "[34]\teval-auc:0.845498\ttrain-auc:0.865495\n",
      "[35]\teval-auc:0.845623\ttrain-auc:0.865734\n",
      "[36]\teval-auc:0.845853\ttrain-auc:0.866116\n",
      "[37]\teval-auc:0.846125\ttrain-auc:0.866470\n",
      "[38]\teval-auc:0.846323\ttrain-auc:0.866874\n",
      "[39]\teval-auc:0.846538\ttrain-auc:0.867235\n",
      "[40]\teval-auc:0.846849\ttrain-auc:0.867662\n",
      "[41]\teval-auc:0.846931\ttrain-auc:0.867863\n",
      "[42]\teval-auc:0.847014\ttrain-auc:0.868024\n",
      "[43]\teval-auc:0.847127\ttrain-auc:0.868252\n",
      "[44]\teval-auc:0.847451\ttrain-auc:0.868708\n",
      "[45]\teval-auc:0.847652\ttrain-auc:0.868982\n",
      "[46]\teval-auc:0.847838\ttrain-auc:0.869278\n",
      "[47]\teval-auc:0.847991\ttrain-auc:0.869587\n",
      "[48]\teval-auc:0.848084\ttrain-auc:0.869806\n",
      "[49]\teval-auc:0.848249\ttrain-auc:0.870010\n",
      "[50]\teval-auc:0.848455\ttrain-auc:0.870359\n",
      "[51]\teval-auc:0.848604\ttrain-auc:0.870613\n",
      "[52]\teval-auc:0.848805\ttrain-auc:0.870941\n",
      "[53]\teval-auc:0.848883\ttrain-auc:0.871142\n",
      "[54]\teval-auc:0.849101\ttrain-auc:0.871473\n",
      "[55]\teval-auc:0.849269\ttrain-auc:0.871737\n",
      "[56]\teval-auc:0.849430\ttrain-auc:0.871970\n",
      "[57]\teval-auc:0.849538\ttrain-auc:0.872192\n",
      "[58]\teval-auc:0.849633\ttrain-auc:0.872361\n",
      "[59]\teval-auc:0.849685\ttrain-auc:0.872506\n",
      "[60]\teval-auc:0.849876\ttrain-auc:0.872879\n",
      "[61]\teval-auc:0.849988\ttrain-auc:0.873044\n",
      "[62]\teval-auc:0.850112\ttrain-auc:0.873247\n",
      "[63]\teval-auc:0.850241\ttrain-auc:0.873445\n",
      "[64]\teval-auc:0.850541\ttrain-auc:0.873874\n",
      "[65]\teval-auc:0.850711\ttrain-auc:0.874168\n",
      "[66]\teval-auc:0.850967\ttrain-auc:0.874509\n",
      "[67]\teval-auc:0.851173\ttrain-auc:0.874840\n",
      "[68]\teval-auc:0.851394\ttrain-auc:0.875163\n",
      "[69]\teval-auc:0.851607\ttrain-auc:0.875465\n",
      "[70]\teval-auc:0.851809\ttrain-auc:0.875806\n",
      "[71]\teval-auc:0.852014\ttrain-auc:0.876104\n",
      "[72]\teval-auc:0.852248\ttrain-auc:0.876366\n",
      "[73]\teval-auc:0.852413\ttrain-auc:0.876748\n",
      "[74]\teval-auc:0.852537\ttrain-auc:0.876984\n",
      "[75]\teval-auc:0.852690\ttrain-auc:0.877263\n",
      "[76]\teval-auc:0.852818\ttrain-auc:0.877549\n",
      "[77]\teval-auc:0.853000\ttrain-auc:0.877841\n",
      "[78]\teval-auc:0.853180\ttrain-auc:0.878105\n",
      "[79]\teval-auc:0.853393\ttrain-auc:0.878436\n",
      "[80]\teval-auc:0.853534\ttrain-auc:0.878723\n",
      "[81]\teval-auc:0.853653\ttrain-auc:0.878902\n",
      "[82]\teval-auc:0.853742\ttrain-auc:0.879086\n",
      "[83]\teval-auc:0.853889\ttrain-auc:0.879348\n",
      "[84]\teval-auc:0.854135\ttrain-auc:0.879644\n",
      "[85]\teval-auc:0.854318\ttrain-auc:0.879911\n",
      "[86]\teval-auc:0.854611\ttrain-auc:0.880363\n",
      "[87]\teval-auc:0.854740\ttrain-auc:0.880545\n",
      "[88]\teval-auc:0.854915\ttrain-auc:0.880782\n",
      "[89]\teval-auc:0.855084\ttrain-auc:0.881011\n",
      "[90]\teval-auc:0.855311\ttrain-auc:0.881365\n",
      "[91]\teval-auc:0.855434\ttrain-auc:0.881619\n",
      "[92]\teval-auc:0.855540\ttrain-auc:0.881809\n",
      "[93]\teval-auc:0.855705\ttrain-auc:0.882136\n",
      "[94]\teval-auc:0.855920\ttrain-auc:0.882468\n",
      "[95]\teval-auc:0.856133\ttrain-auc:0.882796\n",
      "[96]\teval-auc:0.856263\ttrain-auc:0.883010\n",
      "[97]\teval-auc:0.856422\ttrain-auc:0.883248\n",
      "[98]\teval-auc:0.856536\ttrain-auc:0.883500\n",
      "[99]\teval-auc:0.856654\ttrain-auc:0.883732\n",
      "[100]\teval-auc:0.856817\ttrain-auc:0.884005\n",
      "[101]\teval-auc:0.856962\ttrain-auc:0.884231\n",
      "[102]\teval-auc:0.857123\ttrain-auc:0.884479\n",
      "[103]\teval-auc:0.857304\ttrain-auc:0.884788\n",
      "[104]\teval-auc:0.857467\ttrain-auc:0.885107\n",
      "[105]\teval-auc:0.857681\ttrain-auc:0.885388\n",
      "[106]\teval-auc:0.857817\ttrain-auc:0.885635\n",
      "[107]\teval-auc:0.857985\ttrain-auc:0.885894\n",
      "[108]\teval-auc:0.858153\ttrain-auc:0.886182\n",
      "[109]\teval-auc:0.858237\ttrain-auc:0.886377\n",
      "[110]\teval-auc:0.858370\ttrain-auc:0.886586\n",
      "[111]\teval-auc:0.858528\ttrain-auc:0.886817\n",
      "[112]\teval-auc:0.858663\ttrain-auc:0.887024\n",
      "[113]\teval-auc:0.858857\ttrain-auc:0.887319\n",
      "[114]\teval-auc:0.858962\ttrain-auc:0.887517\n",
      "[115]\teval-auc:0.859121\ttrain-auc:0.887767\n",
      "[116]\teval-auc:0.859252\ttrain-auc:0.887994\n",
      "[117]\teval-auc:0.859440\ttrain-auc:0.888305\n",
      "[118]\teval-auc:0.859572\ttrain-auc:0.888547\n",
      "[119]\teval-auc:0.859773\ttrain-auc:0.888854\n",
      "[120]\teval-auc:0.859869\ttrain-auc:0.889070\n",
      "[121]\teval-auc:0.859996\ttrain-auc:0.889282\n",
      "[122]\teval-auc:0.860128\ttrain-auc:0.889457\n",
      "[123]\teval-auc:0.860234\ttrain-auc:0.889688\n",
      "[124]\teval-auc:0.860381\ttrain-auc:0.889886\n",
      "[125]\teval-auc:0.860534\ttrain-auc:0.890193\n",
      "[126]\teval-auc:0.860729\ttrain-auc:0.890469\n",
      "[127]\teval-auc:0.860844\ttrain-auc:0.890662\n",
      "[128]\teval-auc:0.860918\ttrain-auc:0.890826\n",
      "[129]\teval-auc:0.861066\ttrain-auc:0.891049\n",
      "[130]\teval-auc:0.861192\ttrain-auc:0.891265\n",
      "[131]\teval-auc:0.861365\ttrain-auc:0.891513\n",
      "[132]\teval-auc:0.861433\ttrain-auc:0.891737\n",
      "[133]\teval-auc:0.861528\ttrain-auc:0.891888\n",
      "[134]\teval-auc:0.861631\ttrain-auc:0.892083\n",
      "[135]\teval-auc:0.861786\ttrain-auc:0.892338\n",
      "[136]\teval-auc:0.861901\ttrain-auc:0.892575\n",
      "[137]\teval-auc:0.862084\ttrain-auc:0.892842\n",
      "[138]\teval-auc:0.862181\ttrain-auc:0.893014\n",
      "[139]\teval-auc:0.862358\ttrain-auc:0.893255\n",
      "[140]\teval-auc:0.862500\ttrain-auc:0.893464\n",
      "[141]\teval-auc:0.862641\ttrain-auc:0.893708\n",
      "[142]\teval-auc:0.862890\ttrain-auc:0.894000\n",
      "[143]\teval-auc:0.863040\ttrain-auc:0.894229\n",
      "[144]\teval-auc:0.863156\ttrain-auc:0.894413\n",
      "[145]\teval-auc:0.863252\ttrain-auc:0.894612\n",
      "[146]\teval-auc:0.863376\ttrain-auc:0.894852\n",
      "[147]\teval-auc:0.863533\ttrain-auc:0.895101\n",
      "[148]\teval-auc:0.863664\ttrain-auc:0.895326\n",
      "[149]\teval-auc:0.863746\ttrain-auc:0.895508\n",
      "[150]\teval-auc:0.863899\ttrain-auc:0.895738\n",
      "[151]\teval-auc:0.864001\ttrain-auc:0.896017\n",
      "[152]\teval-auc:0.864119\ttrain-auc:0.896243\n",
      "[153]\teval-auc:0.864254\ttrain-auc:0.896442\n",
      "[154]\teval-auc:0.864370\ttrain-auc:0.896697\n",
      "[155]\teval-auc:0.864521\ttrain-auc:0.896917\n",
      "[156]\teval-auc:0.864661\ttrain-auc:0.897184\n",
      "[157]\teval-auc:0.864760\ttrain-auc:0.897377\n",
      "[158]\teval-auc:0.864891\ttrain-auc:0.897642\n",
      "[159]\teval-auc:0.865061\ttrain-auc:0.897872\n",
      "[160]\teval-auc:0.865126\ttrain-auc:0.898041\n",
      "[161]\teval-auc:0.865207\ttrain-auc:0.898207\n",
      "[162]\teval-auc:0.865311\ttrain-auc:0.898417\n",
      "[163]\teval-auc:0.865443\ttrain-auc:0.898616\n",
      "[164]\teval-auc:0.865616\ttrain-auc:0.898883\n",
      "[165]\teval-auc:0.865724\ttrain-auc:0.899121\n",
      "[166]\teval-auc:0.865819\ttrain-auc:0.899279\n",
      "[167]\teval-auc:0.865953\ttrain-auc:0.899477\n",
      "[168]\teval-auc:0.866048\ttrain-auc:0.899689\n",
      "[169]\teval-auc:0.866193\ttrain-auc:0.899927\n",
      "[170]\teval-auc:0.866290\ttrain-auc:0.900088\n",
      "[171]\teval-auc:0.866365\ttrain-auc:0.900319\n",
      "[172]\teval-auc:0.866635\ttrain-auc:0.900642\n",
      "[173]\teval-auc:0.866723\ttrain-auc:0.900799\n",
      "[174]\teval-auc:0.866855\ttrain-auc:0.901029\n",
      "[175]\teval-auc:0.867000\ttrain-auc:0.901219\n",
      "[176]\teval-auc:0.867108\ttrain-auc:0.901436\n",
      "[177]\teval-auc:0.867259\ttrain-auc:0.901686\n",
      "[178]\teval-auc:0.867338\ttrain-auc:0.901805\n",
      "[179]\teval-auc:0.867420\ttrain-auc:0.901952\n",
      "[180]\teval-auc:0.867566\ttrain-auc:0.902148\n",
      "[181]\teval-auc:0.867688\ttrain-auc:0.902361\n",
      "[182]\teval-auc:0.867827\ttrain-auc:0.902569\n",
      "[183]\teval-auc:0.867997\ttrain-auc:0.902808\n",
      "[184]\teval-auc:0.868089\ttrain-auc:0.902938\n",
      "[185]\teval-auc:0.868175\ttrain-auc:0.903116\n",
      "[186]\teval-auc:0.868236\ttrain-auc:0.903244\n",
      "[187]\teval-auc:0.868300\ttrain-auc:0.903368\n",
      "[188]\teval-auc:0.868408\ttrain-auc:0.903526\n",
      "[189]\teval-auc:0.868521\ttrain-auc:0.903778\n",
      "[190]\teval-auc:0.868609\ttrain-auc:0.903919\n",
      "[191]\teval-auc:0.868684\ttrain-auc:0.904047\n",
      "[192]\teval-auc:0.868764\ttrain-auc:0.904270\n",
      "[193]\teval-auc:0.868845\ttrain-auc:0.904435\n",
      "[194]\teval-auc:0.868925\ttrain-auc:0.904625\n",
      "[195]\teval-auc:0.869033\ttrain-auc:0.904776\n",
      "[196]\teval-auc:0.869157\ttrain-auc:0.904948\n",
      "[197]\teval-auc:0.869286\ttrain-auc:0.905119\n",
      "[198]\teval-auc:0.869409\ttrain-auc:0.905320\n",
      "[199]\teval-auc:0.869469\ttrain-auc:0.905506\n",
      "[200]\teval-auc:0.869558\ttrain-auc:0.905720\n",
      "[201]\teval-auc:0.869644\ttrain-auc:0.905875\n",
      "[202]\teval-auc:0.869733\ttrain-auc:0.906042\n",
      "[203]\teval-auc:0.869838\ttrain-auc:0.906184\n",
      "[204]\teval-auc:0.869914\ttrain-auc:0.906396\n",
      "[205]\teval-auc:0.870006\ttrain-auc:0.906618\n",
      "[206]\teval-auc:0.870082\ttrain-auc:0.906765\n",
      "[207]\teval-auc:0.870185\ttrain-auc:0.906906\n",
      "[208]\teval-auc:0.870332\ttrain-auc:0.907095\n",
      "[209]\teval-auc:0.870428\ttrain-auc:0.907213\n",
      "[210]\teval-auc:0.870531\ttrain-auc:0.907417\n",
      "[211]\teval-auc:0.870614\ttrain-auc:0.907571\n",
      "[212]\teval-auc:0.870687\ttrain-auc:0.907695\n",
      "[213]\teval-auc:0.870769\ttrain-auc:0.907854\n",
      "[214]\teval-auc:0.870885\ttrain-auc:0.907995\n",
      "[215]\teval-auc:0.870942\ttrain-auc:0.908152\n",
      "[216]\teval-auc:0.871051\ttrain-auc:0.908332\n",
      "[217]\teval-auc:0.871129\ttrain-auc:0.908490\n",
      "[218]\teval-auc:0.871258\ttrain-auc:0.908633\n",
      "[219]\teval-auc:0.871374\ttrain-auc:0.908826\n",
      "[220]\teval-auc:0.871448\ttrain-auc:0.908954\n",
      "[221]\teval-auc:0.871560\ttrain-auc:0.909110\n",
      "[222]\teval-auc:0.871685\ttrain-auc:0.909266\n",
      "[223]\teval-auc:0.871733\ttrain-auc:0.909332\n",
      "[224]\teval-auc:0.871814\ttrain-auc:0.909499\n",
      "[225]\teval-auc:0.871884\ttrain-auc:0.909618\n",
      "[226]\teval-auc:0.871959\ttrain-auc:0.909803\n",
      "[227]\teval-auc:0.872159\ttrain-auc:0.910019\n",
      "[228]\teval-auc:0.872239\ttrain-auc:0.910159\n",
      "[229]\teval-auc:0.872324\ttrain-auc:0.910315\n",
      "[230]\teval-auc:0.872383\ttrain-auc:0.910481\n",
      "[231]\teval-auc:0.872518\ttrain-auc:0.910630\n",
      "[232]\teval-auc:0.872658\ttrain-auc:0.910799\n",
      "[233]\teval-auc:0.872695\ttrain-auc:0.910874\n",
      "[234]\teval-auc:0.872744\ttrain-auc:0.910975\n",
      "[235]\teval-auc:0.872816\ttrain-auc:0.911096\n",
      "[236]\teval-auc:0.872865\ttrain-auc:0.911176\n",
      "[237]\teval-auc:0.872976\ttrain-auc:0.911325\n",
      "[238]\teval-auc:0.873011\ttrain-auc:0.911406\n",
      "[239]\teval-auc:0.873129\ttrain-auc:0.911590\n",
      "[240]\teval-auc:0.873251\ttrain-auc:0.911780\n",
      "[241]\teval-auc:0.873312\ttrain-auc:0.911969\n",
      "[242]\teval-auc:0.873427\ttrain-auc:0.912126\n",
      "[243]\teval-auc:0.873511\ttrain-auc:0.912279\n",
      "[244]\teval-auc:0.873586\ttrain-auc:0.912422\n",
      "[245]\teval-auc:0.873710\ttrain-auc:0.912577\n",
      "[246]\teval-auc:0.873755\ttrain-auc:0.912734\n",
      "[247]\teval-auc:0.873868\ttrain-auc:0.912864\n",
      "[248]\teval-auc:0.873928\ttrain-auc:0.912937\n",
      "[249]\teval-auc:0.873980\ttrain-auc:0.913060\n",
      "[250]\teval-auc:0.874038\ttrain-auc:0.913140\n",
      "[251]\teval-auc:0.874097\ttrain-auc:0.913258\n",
      "[252]\teval-auc:0.874144\ttrain-auc:0.913310\n",
      "[253]\teval-auc:0.874176\ttrain-auc:0.913389\n",
      "[254]\teval-auc:0.874263\ttrain-auc:0.913548\n",
      "[255]\teval-auc:0.874340\ttrain-auc:0.913651\n",
      "[256]\teval-auc:0.874490\ttrain-auc:0.913824\n",
      "[257]\teval-auc:0.874551\ttrain-auc:0.913958\n",
      "[258]\teval-auc:0.874643\ttrain-auc:0.914086\n",
      "[259]\teval-auc:0.874695\ttrain-auc:0.914200\n",
      "[260]\teval-auc:0.874752\ttrain-auc:0.914304\n",
      "[261]\teval-auc:0.874840\ttrain-auc:0.914457\n",
      "[262]\teval-auc:0.874963\ttrain-auc:0.914603\n",
      "[263]\teval-auc:0.875029\ttrain-auc:0.914696\n",
      "[264]\teval-auc:0.875136\ttrain-auc:0.914807\n",
      "[265]\teval-auc:0.875223\ttrain-auc:0.914974\n",
      "[266]\teval-auc:0.875276\ttrain-auc:0.915060\n",
      "[267]\teval-auc:0.875344\ttrain-auc:0.915143\n",
      "[268]\teval-auc:0.875465\ttrain-auc:0.915361\n",
      "[269]\teval-auc:0.875507\ttrain-auc:0.915490\n",
      "[270]\teval-auc:0.875612\ttrain-auc:0.915655\n",
      "[271]\teval-auc:0.875730\ttrain-auc:0.915844\n",
      "[272]\teval-auc:0.875815\ttrain-auc:0.915961\n",
      "[273]\teval-auc:0.875883\ttrain-auc:0.916053\n",
      "[274]\teval-auc:0.875953\ttrain-auc:0.916175\n",
      "[275]\teval-auc:0.876098\ttrain-auc:0.916367\n",
      "[276]\teval-auc:0.876145\ttrain-auc:0.916437\n",
      "[277]\teval-auc:0.876213\ttrain-auc:0.916561\n",
      "[278]\teval-auc:0.876267\ttrain-auc:0.916658\n",
      "[279]\teval-auc:0.876329\ttrain-auc:0.916719\n",
      "[280]\teval-auc:0.876366\ttrain-auc:0.916787\n",
      "[281]\teval-auc:0.876460\ttrain-auc:0.916924\n",
      "[282]\teval-auc:0.876527\ttrain-auc:0.917041\n",
      "[283]\teval-auc:0.876576\ttrain-auc:0.917207\n",
      "[284]\teval-auc:0.876637\ttrain-auc:0.917296\n",
      "[285]\teval-auc:0.876699\ttrain-auc:0.917490\n",
      "[286]\teval-auc:0.876746\ttrain-auc:0.917623\n",
      "[287]\teval-auc:0.876812\ttrain-auc:0.917701\n",
      "[288]\teval-auc:0.876838\ttrain-auc:0.917774\n",
      "[289]\teval-auc:0.876916\ttrain-auc:0.917970\n",
      "[290]\teval-auc:0.876971\ttrain-auc:0.918031\n",
      "[291]\teval-auc:0.876996\ttrain-auc:0.918133\n",
      "[292]\teval-auc:0.877051\ttrain-auc:0.918219\n",
      "[293]\teval-auc:0.877067\ttrain-auc:0.918272\n",
      "[294]\teval-auc:0.877092\ttrain-auc:0.918392\n",
      "[295]\teval-auc:0.877138\ttrain-auc:0.918458\n",
      "[296]\teval-auc:0.877165\ttrain-auc:0.918515\n",
      "[297]\teval-auc:0.877244\ttrain-auc:0.918630\n",
      "[298]\teval-auc:0.877300\ttrain-auc:0.918703\n",
      "[299]\teval-auc:0.877347\ttrain-auc:0.918833\n",
      "[300]\teval-auc:0.877397\ttrain-auc:0.918981\n",
      "[301]\teval-auc:0.877437\ttrain-auc:0.919044\n",
      "[302]\teval-auc:0.877537\ttrain-auc:0.919198\n",
      "[303]\teval-auc:0.877570\ttrain-auc:0.919261\n",
      "[304]\teval-auc:0.877588\ttrain-auc:0.919290\n",
      "[305]\teval-auc:0.877673\ttrain-auc:0.919392\n",
      "[306]\teval-auc:0.877753\ttrain-auc:0.919534\n",
      "[307]\teval-auc:0.877846\ttrain-auc:0.919657\n",
      "[308]\teval-auc:0.877894\ttrain-auc:0.919772\n",
      "[309]\teval-auc:0.877967\ttrain-auc:0.919884\n",
      "[310]\teval-auc:0.878016\ttrain-auc:0.920023\n",
      "[311]\teval-auc:0.878063\ttrain-auc:0.920182\n",
      "[312]\teval-auc:0.878113\ttrain-auc:0.920264\n",
      "[313]\teval-auc:0.878181\ttrain-auc:0.920367\n",
      "[314]\teval-auc:0.878224\ttrain-auc:0.920473\n",
      "[315]\teval-auc:0.878275\ttrain-auc:0.920531\n",
      "[316]\teval-auc:0.878341\ttrain-auc:0.920609\n",
      "[317]\teval-auc:0.878432\ttrain-auc:0.920753\n",
      "[318]\teval-auc:0.878444\ttrain-auc:0.920778\n",
      "[319]\teval-auc:0.878514\ttrain-auc:0.920868\n",
      "[320]\teval-auc:0.878583\ttrain-auc:0.920947\n",
      "[321]\teval-auc:0.878677\ttrain-auc:0.921119\n",
      "[322]\teval-auc:0.878766\ttrain-auc:0.921290\n",
      "[323]\teval-auc:0.878898\ttrain-auc:0.921479\n",
      "[324]\teval-auc:0.878941\ttrain-auc:0.921531\n",
      "[325]\teval-auc:0.878982\ttrain-auc:0.921651\n",
      "[326]\teval-auc:0.879011\ttrain-auc:0.921703\n",
      "[327]\teval-auc:0.879041\ttrain-auc:0.921796\n",
      "[328]\teval-auc:0.879112\ttrain-auc:0.921898\n",
      "[329]\teval-auc:0.879179\ttrain-auc:0.922013\n",
      "[330]\teval-auc:0.879228\ttrain-auc:0.922159\n",
      "[331]\teval-auc:0.879318\ttrain-auc:0.922300\n",
      "[332]\teval-auc:0.879370\ttrain-auc:0.922393\n",
      "[333]\teval-auc:0.879464\ttrain-auc:0.922532\n",
      "[334]\teval-auc:0.879502\ttrain-auc:0.922616\n",
      "[335]\teval-auc:0.879538\ttrain-auc:0.922699\n",
      "[336]\teval-auc:0.879597\ttrain-auc:0.922800\n",
      "[337]\teval-auc:0.879672\ttrain-auc:0.922922\n",
      "[338]\teval-auc:0.879737\ttrain-auc:0.923040\n",
      "[339]\teval-auc:0.879790\ttrain-auc:0.923141\n",
      "[340]\teval-auc:0.879816\ttrain-auc:0.923209\n",
      "[341]\teval-auc:0.879846\ttrain-auc:0.923291\n",
      "[342]\teval-auc:0.879877\ttrain-auc:0.923340\n",
      "[343]\teval-auc:0.879906\ttrain-auc:0.923388\n",
      "[344]\teval-auc:0.879964\ttrain-auc:0.923455\n",
      "[345]\teval-auc:0.879991\ttrain-auc:0.923487\n",
      "[346]\teval-auc:0.880028\ttrain-auc:0.923553\n",
      "[347]\teval-auc:0.880060\ttrain-auc:0.923625\n",
      "[348]\teval-auc:0.880091\ttrain-auc:0.923667\n",
      "[349]\teval-auc:0.880137\ttrain-auc:0.923774\n",
      "[350]\teval-auc:0.880154\ttrain-auc:0.923810\n",
      "[351]\teval-auc:0.880192\ttrain-auc:0.923885\n",
      "[352]\teval-auc:0.880296\ttrain-auc:0.924013\n",
      "[353]\teval-auc:0.880317\ttrain-auc:0.924040\n",
      "[354]\teval-auc:0.880338\ttrain-auc:0.924093\n",
      "[355]\teval-auc:0.880365\ttrain-auc:0.924129\n",
      "[356]\teval-auc:0.880429\ttrain-auc:0.924261\n",
      "[357]\teval-auc:0.880445\ttrain-auc:0.924287\n",
      "[358]\teval-auc:0.880506\ttrain-auc:0.924371\n",
      "[359]\teval-auc:0.880617\ttrain-auc:0.924487\n",
      "[360]\teval-auc:0.880666\ttrain-auc:0.924605\n",
      "[361]\teval-auc:0.880720\ttrain-auc:0.924662\n",
      "[362]\teval-auc:0.880772\ttrain-auc:0.924725\n",
      "[363]\teval-auc:0.880818\ttrain-auc:0.924777\n",
      "[364]\teval-auc:0.880873\ttrain-auc:0.924853\n",
      "[365]\teval-auc:0.880938\ttrain-auc:0.924948\n",
      "[366]\teval-auc:0.880993\ttrain-auc:0.925056\n",
      "[367]\teval-auc:0.881037\ttrain-auc:0.925099\n",
      "[368]\teval-auc:0.881069\ttrain-auc:0.925192\n",
      "[369]\teval-auc:0.881095\ttrain-auc:0.925226\n",
      "[370]\teval-auc:0.881131\ttrain-auc:0.925291\n",
      "[371]\teval-auc:0.881280\ttrain-auc:0.925468\n",
      "[372]\teval-auc:0.881369\ttrain-auc:0.925568\n",
      "[373]\teval-auc:0.881385\ttrain-auc:0.925593\n",
      "[374]\teval-auc:0.881426\ttrain-auc:0.925682\n",
      "[375]\teval-auc:0.881473\ttrain-auc:0.925740\n",
      "[376]\teval-auc:0.881511\ttrain-auc:0.925817\n",
      "[377]\teval-auc:0.881555\ttrain-auc:0.925887\n",
      "[378]\teval-auc:0.881598\ttrain-auc:0.925956\n",
      "[379]\teval-auc:0.881664\ttrain-auc:0.926095\n",
      "[380]\teval-auc:0.881735\ttrain-auc:0.926240\n",
      "[381]\teval-auc:0.881803\ttrain-auc:0.926370\n",
      "[382]\teval-auc:0.881808\ttrain-auc:0.926377\n",
      "[383]\teval-auc:0.881845\ttrain-auc:0.926429\n",
      "[384]\teval-auc:0.881914\ttrain-auc:0.926565\n",
      "[385]\teval-auc:0.881982\ttrain-auc:0.926653\n",
      "[386]\teval-auc:0.882012\ttrain-auc:0.926699\n",
      "[387]\teval-auc:0.882041\ttrain-auc:0.926776\n",
      "[388]\teval-auc:0.882090\ttrain-auc:0.926847\n",
      "[389]\teval-auc:0.882119\ttrain-auc:0.926903\n",
      "[390]\teval-auc:0.882159\ttrain-auc:0.926966\n",
      "[391]\teval-auc:0.882267\ttrain-auc:0.927101\n",
      "[392]\teval-auc:0.882293\ttrain-auc:0.927145\n",
      "[393]\teval-auc:0.882362\ttrain-auc:0.927294\n",
      "[394]\teval-auc:0.882399\ttrain-auc:0.927388\n",
      "[395]\teval-auc:0.882410\ttrain-auc:0.927407\n",
      "[396]\teval-auc:0.882453\ttrain-auc:0.927473\n",
      "[397]\teval-auc:0.882499\ttrain-auc:0.927527\n",
      "[398]\teval-auc:0.882553\ttrain-auc:0.927608\n",
      "[399]\teval-auc:0.882574\ttrain-auc:0.927669\n",
      "[400]\teval-auc:0.882586\ttrain-auc:0.927703\n",
      "[401]\teval-auc:0.882600\ttrain-auc:0.927732\n",
      "[402]\teval-auc:0.882640\ttrain-auc:0.927799\n",
      "[403]\teval-auc:0.882740\ttrain-auc:0.927930\n",
      "[404]\teval-auc:0.882750\ttrain-auc:0.927946\n",
      "[405]\teval-auc:0.882798\ttrain-auc:0.928031\n",
      "[406]\teval-auc:0.882846\ttrain-auc:0.928114\n",
      "[407]\teval-auc:0.882866\ttrain-auc:0.928139\n",
      "[408]\teval-auc:0.882923\ttrain-auc:0.928309\n",
      "[409]\teval-auc:0.883050\ttrain-auc:0.928452\n",
      "[410]\teval-auc:0.883129\ttrain-auc:0.928571\n",
      "[411]\teval-auc:0.883188\ttrain-auc:0.928681\n",
      "[412]\teval-auc:0.883224\ttrain-auc:0.928734\n",
      "[413]\teval-auc:0.883247\ttrain-auc:0.928764\n",
      "[414]\teval-auc:0.883266\ttrain-auc:0.928822\n",
      "[415]\teval-auc:0.883272\ttrain-auc:0.928835\n",
      "[416]\teval-auc:0.883345\ttrain-auc:0.928964\n",
      "[417]\teval-auc:0.883364\ttrain-auc:0.928988\n",
      "[418]\teval-auc:0.883390\ttrain-auc:0.929016\n",
      "[419]\teval-auc:0.883416\ttrain-auc:0.929092\n",
      "[420]\teval-auc:0.883441\ttrain-auc:0.929129\n",
      "[421]\teval-auc:0.883453\ttrain-auc:0.929146\n",
      "[422]\teval-auc:0.883550\ttrain-auc:0.929275\n",
      "[423]\teval-auc:0.883623\ttrain-auc:0.929404\n",
      "[424]\teval-auc:0.883739\ttrain-auc:0.929545\n",
      "[425]\teval-auc:0.883795\ttrain-auc:0.929640\n",
      "[426]\teval-auc:0.883859\ttrain-auc:0.929727\n",
      "[427]\teval-auc:0.884007\ttrain-auc:0.929923\n",
      "[428]\teval-auc:0.884025\ttrain-auc:0.929964\n",
      "[429]\teval-auc:0.884037\ttrain-auc:0.929981\n",
      "[430]\teval-auc:0.884102\ttrain-auc:0.930074\n",
      "[431]\teval-auc:0.884180\ttrain-auc:0.930184\n",
      "[432]\teval-auc:0.884246\ttrain-auc:0.930255\n",
      "[433]\teval-auc:0.884262\ttrain-auc:0.930270\n",
      "[434]\teval-auc:0.884336\ttrain-auc:0.930384\n",
      "[435]\teval-auc:0.884363\ttrain-auc:0.930421\n",
      "[436]\teval-auc:0.884377\ttrain-auc:0.930438\n",
      "[437]\teval-auc:0.884432\ttrain-auc:0.930548\n",
      "[438]\teval-auc:0.884495\ttrain-auc:0.930634\n",
      "[439]\teval-auc:0.884517\ttrain-auc:0.930682\n",
      "[440]\teval-auc:0.884546\ttrain-auc:0.930724\n",
      "[441]\teval-auc:0.884632\ttrain-auc:0.930835\n",
      "[442]\teval-auc:0.884667\ttrain-auc:0.930881\n",
      "[443]\teval-auc:0.884760\ttrain-auc:0.930999\n",
      "[444]\teval-auc:0.884794\ttrain-auc:0.931056\n",
      "[445]\teval-auc:0.884815\ttrain-auc:0.931086\n",
      "[446]\teval-auc:0.884875\ttrain-auc:0.931153\n",
      "[447]\teval-auc:0.884896\ttrain-auc:0.931192\n",
      "[448]\teval-auc:0.884959\ttrain-auc:0.931341\n",
      "[449]\teval-auc:0.884994\ttrain-auc:0.931399\n",
      "[450]\teval-auc:0.885057\ttrain-auc:0.931539\n",
      "[451]\teval-auc:0.885146\ttrain-auc:0.931711\n",
      "[452]\teval-auc:0.885206\ttrain-auc:0.931786\n",
      "[453]\teval-auc:0.885324\ttrain-auc:0.931922\n",
      "[454]\teval-auc:0.885369\ttrain-auc:0.932026\n",
      "[455]\teval-auc:0.885423\ttrain-auc:0.932145\n",
      "[456]\teval-auc:0.885445\ttrain-auc:0.932228\n",
      "[457]\teval-auc:0.885481\ttrain-auc:0.932312\n",
      "[458]\teval-auc:0.885524\ttrain-auc:0.932367\n",
      "[459]\teval-auc:0.885547\ttrain-auc:0.932454\n",
      "[460]\teval-auc:0.885600\ttrain-auc:0.932545\n",
      "[461]\teval-auc:0.885653\ttrain-auc:0.932633\n",
      "[462]\teval-auc:0.885671\ttrain-auc:0.932660\n",
      "[463]\teval-auc:0.885701\ttrain-auc:0.932754\n",
      "[464]\teval-auc:0.885746\ttrain-auc:0.932806\n",
      "[465]\teval-auc:0.885776\ttrain-auc:0.932871\n",
      "[466]\teval-auc:0.885807\ttrain-auc:0.932948\n",
      "[467]\teval-auc:0.885893\ttrain-auc:0.933117\n",
      "[468]\teval-auc:0.885951\ttrain-auc:0.933188\n",
      "[469]\teval-auc:0.885962\ttrain-auc:0.933204\n",
      "[470]\teval-auc:0.885980\ttrain-auc:0.933235\n",
      "[471]\teval-auc:0.885993\ttrain-auc:0.933274\n",
      "[472]\teval-auc:0.886010\ttrain-auc:0.933344\n",
      "[473]\teval-auc:0.886046\ttrain-auc:0.933387\n",
      "[474]\teval-auc:0.886065\ttrain-auc:0.933424\n",
      "[475]\teval-auc:0.886156\ttrain-auc:0.933541\n",
      "[476]\teval-auc:0.886168\ttrain-auc:0.933571\n",
      "[477]\teval-auc:0.886183\ttrain-auc:0.933592\n",
      "[478]\teval-auc:0.886232\ttrain-auc:0.933649\n",
      "[479]\teval-auc:0.886244\ttrain-auc:0.933669\n",
      "[480]\teval-auc:0.886251\ttrain-auc:0.933681\n",
      "[481]\teval-auc:0.886281\ttrain-auc:0.933822\n",
      "[482]\teval-auc:0.886317\ttrain-auc:0.933887\n",
      "[483]\teval-auc:0.886331\ttrain-auc:0.933935\n",
      "[484]\teval-auc:0.886349\ttrain-auc:0.933972\n",
      "[485]\teval-auc:0.886366\ttrain-auc:0.934039\n",
      "[486]\teval-auc:0.886413\ttrain-auc:0.934150\n",
      "[487]\teval-auc:0.886476\ttrain-auc:0.934222\n",
      "[488]\teval-auc:0.886526\ttrain-auc:0.934332\n",
      "[489]\teval-auc:0.886536\ttrain-auc:0.934356\n",
      "[490]\teval-auc:0.886552\ttrain-auc:0.934380\n",
      "[491]\teval-auc:0.886558\ttrain-auc:0.934388\n",
      "[492]\teval-auc:0.886568\ttrain-auc:0.934414\n",
      "[493]\teval-auc:0.886653\ttrain-auc:0.934574\n",
      "[494]\teval-auc:0.886735\ttrain-auc:0.934684\n",
      "[495]\teval-auc:0.886752\ttrain-auc:0.934733\n",
      "[496]\teval-auc:0.886763\ttrain-auc:0.934759\n",
      "[497]\teval-auc:0.886768\ttrain-auc:0.934848\n",
      "[498]\teval-auc:0.886792\ttrain-auc:0.934898\n",
      "[499]\teval-auc:0.886822\ttrain-auc:0.934954\n",
      "[500]\teval-auc:0.886839\ttrain-auc:0.934995\n",
      "[501]\teval-auc:0.886855\ttrain-auc:0.935023\n",
      "[502]\teval-auc:0.886911\ttrain-auc:0.935110\n",
      "[503]\teval-auc:0.886952\ttrain-auc:0.935153\n",
      "[504]\teval-auc:0.887024\ttrain-auc:0.935260\n",
      "[505]\teval-auc:0.887092\ttrain-auc:0.935340\n",
      "[506]\teval-auc:0.887097\ttrain-auc:0.935354\n",
      "[507]\teval-auc:0.887154\ttrain-auc:0.935420\n",
      "[508]\teval-auc:0.887196\ttrain-auc:0.935505\n",
      "[509]\teval-auc:0.887231\ttrain-auc:0.935556\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, dtrain, num_round, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving the model\")\n",
    "bst.save_model('./models/xgb_acc_per.model')\n",
    "bst.dump_model('./models/xgb_raw_acc_per.txt')\n",
    "\n",
    "dtrain.save_binary('./models/binary/dtrain.buffer')\n",
    "deval.save_binary('./models/binary/deval.buffer')\n",
    "\n",
    "%xdel dtrain\n",
    "%xdel deval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable           Type        Data/Info\n",
      "----------------------------------------\n",
      "NA                 float       nan\n",
      "Yeval              ndarray     212571: 212571 elems, type `int64`, 1700568 bytes (1.6217880249023438 Mb)\n",
      "Ytrain_c           ndarray     495998: 495998 elems, type `int64`, 3967984 bytes (3.7841644287109375 Mb)\n",
      "auc                function    <function roc_auc_score at 0x7f2f7d8e1ae8>\n",
      "bst                Booster     <xgboost.core.Booster object at 0x7f2f7c887c18>\n",
      "n_dim              int         260\n",
      "n_train            int         708569\n",
      "np                 module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "num_round          int         510\n",
      "os                 module      <module 'os' from '/home/<...>da3/lib/python3.5/os.py'>\n",
      "param              dict        n=10\n",
      "pd                 module      <module 'pandas' from '/h<...>ages/pandas/__init__.py'>\n",
      "plt                module      <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "sns                module      <module 'seaborn' from '/<...>ges/seaborn/__init__.py'>\n",
      "sqlite3            module      <module 'sqlite3' from '/<...>3.5/sqlite3/__init__.py'>\n",
      "train_test_split   function    <function train_test_split at 0x7f2f7c888268>\n",
      "watchlist          list        n=2\n",
      "xgb                module      <module 'xgboost' from '/<...>ges/xgboost/__init__.py'>\n",
      "y                  ndarray     708569: 708569 elems, type `int64`, 5668552 bytes (5.405952453613281 Mb)\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load test samples\n"
     ]
    }
   ],
   "source": [
    "Xtest = pd.read_csv(\"./test/joint_accident_person_test_ext.csv\", index_col=0)\n",
    "ID= Xtest['ID'].astype(np.int64)\n",
    "Xtest.drop('ID', axis= 1, inplace=True)\n",
    "print(\"Load test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqueID = np.unique(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniqueID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest= xgb.DMatrix(data=Xtest.values, missing = NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction\")\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest.save_binary('./models/binary/dtest.buffer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.171901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.254055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.593484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.312187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.191295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.126673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.141163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.028505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.024859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.023092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.635964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>0.090896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>0.102246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>0.071281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>0.076505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>0.074666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>0.047264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>0.227663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>0.346067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>0.231778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>0.142080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>0.133598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>0.213287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>0.029166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.028410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>0.042675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>0.028661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>0.033938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>0.731849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11</td>\n",
       "      <td>0.719551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297649</th>\n",
       "      <td>121052</td>\n",
       "      <td>0.851050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297650</th>\n",
       "      <td>121052</td>\n",
       "      <td>0.848979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297651</th>\n",
       "      <td>121052</td>\n",
       "      <td>0.834162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297652</th>\n",
       "      <td>121053</td>\n",
       "      <td>0.071716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297653</th>\n",
       "      <td>121054</td>\n",
       "      <td>0.708958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297654</th>\n",
       "      <td>121055</td>\n",
       "      <td>0.144201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297655</th>\n",
       "      <td>121055</td>\n",
       "      <td>0.095518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297656</th>\n",
       "      <td>121055</td>\n",
       "      <td>0.077894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297657</th>\n",
       "      <td>121055</td>\n",
       "      <td>0.136868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297658</th>\n",
       "      <td>121056</td>\n",
       "      <td>0.283147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297659</th>\n",
       "      <td>121056</td>\n",
       "      <td>0.326160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297660</th>\n",
       "      <td>121057</td>\n",
       "      <td>0.146388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297661</th>\n",
       "      <td>121057</td>\n",
       "      <td>0.205342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297662</th>\n",
       "      <td>121057</td>\n",
       "      <td>0.144251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297663</th>\n",
       "      <td>121057</td>\n",
       "      <td>0.145227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297664</th>\n",
       "      <td>121057</td>\n",
       "      <td>0.204397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297665</th>\n",
       "      <td>121057</td>\n",
       "      <td>0.220896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297666</th>\n",
       "      <td>121058</td>\n",
       "      <td>0.156272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297667</th>\n",
       "      <td>121059</td>\n",
       "      <td>0.057185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297668</th>\n",
       "      <td>121059</td>\n",
       "      <td>0.033958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297669</th>\n",
       "      <td>121059</td>\n",
       "      <td>0.053150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297670</th>\n",
       "      <td>121060</td>\n",
       "      <td>0.813926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297671</th>\n",
       "      <td>121061</td>\n",
       "      <td>0.109466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297672</th>\n",
       "      <td>121061</td>\n",
       "      <td>0.179647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297673</th>\n",
       "      <td>121062</td>\n",
       "      <td>0.083892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297674</th>\n",
       "      <td>121062</td>\n",
       "      <td>0.138178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297675</th>\n",
       "      <td>121062</td>\n",
       "      <td>0.227696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297676</th>\n",
       "      <td>121063</td>\n",
       "      <td>0.066738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297677</th>\n",
       "      <td>121063</td>\n",
       "      <td>0.052580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297678</th>\n",
       "      <td>121064</td>\n",
       "      <td>0.063277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297679 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID      prob\n",
       "0            0  0.171901\n",
       "1            1  0.254055\n",
       "2            1  0.593484\n",
       "3            1  0.312187\n",
       "4            2  0.191295\n",
       "5            2  0.126673\n",
       "6            2  0.141163\n",
       "7            3  0.028505\n",
       "8            3  0.024859\n",
       "9            4  0.023092\n",
       "10           5  0.635964\n",
       "11           6  0.090896\n",
       "12           6  0.102246\n",
       "13           6  0.071281\n",
       "14           6  0.076505\n",
       "15           7  0.074666\n",
       "16           7  0.047264\n",
       "17           8  0.227663\n",
       "18           8  0.346067\n",
       "19           9  0.231778\n",
       "20           9  0.142080\n",
       "21           9  0.133598\n",
       "22           9  0.213287\n",
       "23          10  0.029166\n",
       "24          10  0.028410\n",
       "25          10  0.042675\n",
       "26          10  0.028661\n",
       "27          10  0.033938\n",
       "28          11  0.731849\n",
       "29          11  0.719551\n",
       "...        ...       ...\n",
       "297649  121052  0.851050\n",
       "297650  121052  0.848979\n",
       "297651  121052  0.834162\n",
       "297652  121053  0.071716\n",
       "297653  121054  0.708958\n",
       "297654  121055  0.144201\n",
       "297655  121055  0.095518\n",
       "297656  121055  0.077894\n",
       "297657  121055  0.136868\n",
       "297658  121056  0.283147\n",
       "297659  121056  0.326160\n",
       "297660  121057  0.146388\n",
       "297661  121057  0.205342\n",
       "297662  121057  0.144251\n",
       "297663  121057  0.145227\n",
       "297664  121057  0.204397\n",
       "297665  121057  0.220896\n",
       "297666  121058  0.156272\n",
       "297667  121059  0.057185\n",
       "297668  121059  0.033958\n",
       "297669  121059  0.053150\n",
       "297670  121060  0.813926\n",
       "297671  121061  0.109466\n",
       "297672  121061  0.179647\n",
       "297673  121062  0.083892\n",
       "297674  121062  0.138178\n",
       "297675  121062  0.227696\n",
       "297676  121063  0.066738\n",
       "297677  121063  0.052580\n",
       "297678  121064  0.063277\n",
       "\n",
       "[297679 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"submit\")\n",
    "predict_df = pd.DataFrame(data={'ID': ID.values, 'prob': preds})\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.171901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.386575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.153044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.635964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.085232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.060965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.286865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.180186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.032570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.725700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.099459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.710856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.103746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.154229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.748396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.031828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.311506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.041332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.502899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.554507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.051618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.069941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.165689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.115129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.266594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.066938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.199861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.067075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121035</th>\n",
       "      <td>0.167666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121036</th>\n",
       "      <td>0.125678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121037</th>\n",
       "      <td>0.114713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121038</th>\n",
       "      <td>0.420304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121039</th>\n",
       "      <td>0.406292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121040</th>\n",
       "      <td>0.048562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121041</th>\n",
       "      <td>0.460840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121042</th>\n",
       "      <td>0.474549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121043</th>\n",
       "      <td>0.199172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121044</th>\n",
       "      <td>0.123813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121045</th>\n",
       "      <td>0.117623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121046</th>\n",
       "      <td>0.640044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121047</th>\n",
       "      <td>0.069642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121048</th>\n",
       "      <td>0.053557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121049</th>\n",
       "      <td>0.022086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121050</th>\n",
       "      <td>0.049023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121051</th>\n",
       "      <td>0.046206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121052</th>\n",
       "      <td>0.827391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121053</th>\n",
       "      <td>0.071716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121054</th>\n",
       "      <td>0.708958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121055</th>\n",
       "      <td>0.113620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121056</th>\n",
       "      <td>0.304654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121057</th>\n",
       "      <td>0.177750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121058</th>\n",
       "      <td>0.156272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121059</th>\n",
       "      <td>0.048098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121060</th>\n",
       "      <td>0.813926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121061</th>\n",
       "      <td>0.144556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121062</th>\n",
       "      <td>0.149922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121063</th>\n",
       "      <td>0.059659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121064</th>\n",
       "      <td>0.063277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121065 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            prob\n",
       "ID              \n",
       "0       0.171901\n",
       "1       0.386575\n",
       "2       0.153044\n",
       "3       0.026682\n",
       "4       0.023092\n",
       "5       0.635964\n",
       "6       0.085232\n",
       "7       0.060965\n",
       "8       0.286865\n",
       "9       0.180186\n",
       "10      0.032570\n",
       "11      0.725700\n",
       "12      0.099459\n",
       "13      0.710856\n",
       "14      0.103746\n",
       "15      0.154229\n",
       "16      0.748396\n",
       "17      0.031828\n",
       "18      0.311506\n",
       "19      0.041332\n",
       "20      0.502899\n",
       "21      0.554507\n",
       "22      0.051618\n",
       "23      0.069941\n",
       "24      0.165689\n",
       "25      0.115129\n",
       "26      0.266594\n",
       "27      0.066938\n",
       "28      0.199861\n",
       "29      0.067075\n",
       "...          ...\n",
       "121035  0.167666\n",
       "121036  0.125678\n",
       "121037  0.114713\n",
       "121038  0.420304\n",
       "121039  0.406292\n",
       "121040  0.048562\n",
       "121041  0.460840\n",
       "121042  0.474549\n",
       "121043  0.199172\n",
       "121044  0.123813\n",
       "121045  0.117623\n",
       "121046  0.640044\n",
       "121047  0.069642\n",
       "121048  0.053557\n",
       "121049  0.022086\n",
       "121050  0.049023\n",
       "121051  0.046206\n",
       "121052  0.827391\n",
       "121053  0.071716\n",
       "121054  0.708958\n",
       "121055  0.113620\n",
       "121056  0.304654\n",
       "121057  0.177750\n",
       "121058  0.156272\n",
       "121059  0.048098\n",
       "121060  0.813926\n",
       "121061  0.144556\n",
       "121062  0.149922\n",
       "121063  0.059659\n",
       "121064  0.063277\n",
       "\n",
       "[121065 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.groupby('ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_predict = predict_df.groupby('ID')\n",
    "prediction = grouped_predict.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
       "                 8,      9,\n",
       "            ...\n",
       "            121055, 121056, 121057, 121058, 121059, 121060, 121061, 121062,\n",
       "            121063, 121064],\n",
       "           dtype='int64', name='ID', length=121065)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(data={'ID': prediction.index, 'DRUNK_DR': prediction})\n",
    "submit.to_csv('fars_submit.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
